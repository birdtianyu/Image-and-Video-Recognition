{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract, Transform, Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and Transform\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root=r'./Dataset',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root=r'./Dataset',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Load\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size = 100,\n",
    "    shuffle = True  # to have the data reshuffled at every epoch\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size = 100,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) \t torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "print(images.shape,'\\t',labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*6*6, out_features=120)\n",
    "        # self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=120, out_features=10)\n",
    "        \n",
    "    def forward(self, d):\n",
    "        # conv1 layer\n",
    "        d = self.conv1(d)\n",
    "        d = nn.functional.relu(d)\n",
    "        d = nn.functional.max_pool2d(d, kernel_size=2, stride=2)\n",
    "    \n",
    "        # conv2 layer\n",
    "        d = self.conv2(d)\n",
    "        d = nn.functional.relu(d)\n",
    "        d = nn.functional.max_pool2d(d, kernel_size=2, stride=2)\n",
    "\n",
    "        # fully connected Layer1\n",
    "        # d = d.reshape(-1, 12*4*4)\n",
    "        d = d.flatten(start_dim=1)\n",
    "        d = self.fc1(d)\n",
    "        d = nn.functional.relu(d)\n",
    "\n",
    "        # fully connected Layer2\n",
    "        # d = self.fc2(d)\n",
    "        # d = nn.functional.relu(d)\n",
    "\n",
    "        # output layer\n",
    "        d = self.out(d)\n",
    "        # d = nn.functional.softmax(d)\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=432, out_features=120, bias=True)\n",
       "  (out): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = ConvNetwork()\n",
    "network.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 30348), started 0:01:24 ago. (Use '!kill 30348' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6c7028ba28d5997\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6c7028ba28d5997\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs/ --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loss_fn, test_loader, device=torch.device(\"cpu\")):\n",
    "    model.eval()\n",
    "\n",
    "    loss = 0.\n",
    "    num_correct = 0.\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss += loss_fn(y_pred, y).item()\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        num_correct += (predicted == y).sum().item()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    loss /= len(test_loader.dataset)\n",
    "    num_correct /= len(test_loader.dataset)\n",
    "    \n",
    "    return loss, num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    '''\n",
    "    Calculate the number of correct predictions\n",
    "    '''\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: loss_test=0.0013, loss_train=0.0014, acc_test=0.9611, acc_train=0.9583\n",
      "#1: loss_test=0.0013, loss_train=0.0013, acc_test=0.9621, acc_train=0.9602\n",
      "#2: loss_test=0.0012, loss_train=0.0012, acc_test=0.9624, acc_train=0.9627\n",
      "#3: loss_test=0.0011, loss_train=0.0012, acc_test=0.9658, acc_train=0.9645\n",
      "#4: loss_test=0.0010, loss_train=0.0011, acc_test=0.9705, acc_train=0.9661\n",
      "#5: loss_test=0.0011, loss_train=0.0010, acc_test=0.9626, acc_train=0.9682\n",
      "#6: loss_test=0.0011, loss_train=0.0010, acc_test=0.9659, acc_train=0.9691\n",
      "#7: loss_test=0.0009, loss_train=0.0009, acc_test=0.9709, acc_train=0.9710\n",
      "#8: loss_test=0.0009, loss_train=0.0009, acc_test=0.9717, acc_train=0.9715\n",
      "#9: loss_test=0.0008, loss_train=0.0009, acc_test=0.9738, acc_train=0.9732\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate\n",
    "lr = 0.008\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr) \n",
    "\n",
    "# tensorboard\n",
    "tb = SummaryWriter(comment=\"My CNN\")\n",
    "\n",
    "# images, labels = next(iter(train_loader))\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "# Training times\n",
    "for epoch in range(10):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        preds = network(images)\n",
    "        \n",
    "        # Compute the loss value.\n",
    "        loss = loss_function(preds, labels)\n",
    "        train_loss += loss.item()\n",
    "        train_correct += get_num_correct(preds, labels)\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.zero_grad()  # Initialize to zero.\n",
    "        loss.backward()\n",
    "        optimizer.step()       # Updating the weights\n",
    "        \n",
    "        \n",
    "    # Compute the average loss and accuracy.\n",
    "    train_loss /= len(train_set)\n",
    "    train_correct /= float(len(train_set))\n",
    "    \n",
    "    # Evaluate the model on the test set.\n",
    "    test_loss, test_correct = test_model(network, loss_function, test_loader, device)\n",
    "    \n",
    "    # Record loss and accuracy values on the training and test sets.\n",
    "    tb.add_scalars('loss', {'train': train_loss, 'test': test_loss}, epoch)\n",
    "    tb.add_scalars('accuracy', {'train': train_correct, 'test': test_correct}, epoch)\n",
    "    \n",
    "    # Report progress\n",
    "    print(f'#{epoch}: loss_test={test_loss:.4f}, loss_train={train_loss:.4f}, acc_test={test_correct:.4f}, acc_train={train_correct:.4f}')\n",
    "    \n",
    "    \n",
    "# Don't forget it!\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
